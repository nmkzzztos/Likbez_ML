{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\">Naive Bayes algorithm</h1>\n",
    "\n",
    "<p style=\"text-align: center\">Naive Bayes is a simple probabilistic classifier based on applying Bayes' theorem with <strong>strong (naive) independence assumptions between the features</strong>. It is easy to build and particularly useful for very large data sets. Along with other linear classifiers, Naive Bayes is a good baseline classifier to which more sophisticated methods can be compared.\n",
    "<br>\n",
    "<br>\n",
    "The Naive Bayes classifier is highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. In particular, the parameters of the model are estimated using a \"closed-form\" expression, which takes linear time, rather than iterative approximation as used for many other types of classifiers. This makes it particularly useful for very large data sets. The model is also relatively robust, requiring only a small number of training data to estimate the necessary parameters.\n",
    "<br>\n",
    "<br>\n",
    "To classify a new object we'll use the following Naive Bayes formula: <br>\n",
    "</p>\n",
    "\n",
    "$$P(C_k|x_1, x_2, ..., x_n) = \\frac{P(x_1, x_2, ..., x_n|C_k)P(C_k)}{P(x_1, x_2, ..., x_n)}$$\n",
    "\n",
    "$$P(C_k|x_1, x_2, ..., x_n): \\text{posterior probability - probability of class given features}$$\n",
    "$$C_k: \\text{class}$$\n",
    "$$x_i: \\text{feature}$$\n",
    "$$P(x_i|C_k): \\text{likelihood - probability of feature given class}$$\n",
    "$$P(C_k): \\text{prior probability - probability of class}$$\n",
    "$$P(x_i): \\text{marginal probability - probability of feature (it can be ignored)}$$\n",
    "\n",
    "<p align=\"center\"><img src=\"../../assets/NaiveBayes/example.png\"></p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "We have 2 classes: spam and not spam(ham) and 2 features: contains word \"free\" and contains word \"money\", we want to classify new email, which class it belongs to (spam or ham) and what is the probability of this class.\n",
    "\n",
    "|      | Spam | Ham  | Total|\n",
    "|------|------|------| -----|\n",
    "| Free | 2    | 20   | 22   |\n",
    "| Money| 5    | 10   | 15   |\n",
    "| Total| 10   | 90   | 100  |\n",
    "\n",
    "$$Priors:\\;P(Spam) = \\frac{10}{100} = 0.1,\\;P(Ham) = \\frac{90}{100} = 0.9$$\n",
    "$$Likelihood-money:\\;P(Free|Spam) = \\frac{2}{10} = 0.2,\\;P(Free|Ham) = \\frac{20}{90} = 0.22$$\n",
    "$$Likelihood-free:\\;P(Money|Spam) = \\frac{5}{10} = 0.5,\\;P(Money|Ham) = \\frac{10}{90} = 0.11$$\n",
    "$$Posterior:\\;P(Spam|Free, Money) = P(Free, Money|Spam)P(Spam) = 0.2 \\cdot 0.5 \\cdot 0.1 = 0.01$$\n",
    "$$Posterior:\\;P(Ham|Free, Money) = P(Free, Money|Ham)P(Ham) = 0.22 \\cdot 0.11 \\cdot 0.9 = 0.02$$\n",
    "$$P(Ham|Free, Money) > P(Spam|Free, Money) => \\text{so we classify new email as Ham with probability 0.02}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, stop_words=[]):\n",
    "        self.labels = []\n",
    "        self.likelihoods = {}\n",
    "        self.priors = {}\n",
    "        self.stop_words = []\n",
    "\n",
    "    def _preprocess_text_(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess a text by removing punctuation, numbers, and stop words and returning a list of words\n",
    "\n",
    "        Args:\n",
    "            text (float): text to preprocess\n",
    "\n",
    "        Returns: list: List of preprocessed words\n",
    "        \"\"\" \n",
    "        text = str(text)\n",
    "        text = text.encode('ascii', errors='replace').decode('ascii')\n",
    "        text = text.lower()\n",
    "        text = ''.join([c for c in text if c not in '0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'])\n",
    "        text = ' '.join([word for word in text.split() if word not in self.stop_words])\n",
    "\n",
    "        return text.split()\n",
    "    \n",
    "    def _likelihoods_ (self, X, y):\n",
    "        '''\n",
    "        Calculate the likelihoods of each word in each class\n",
    "        \n",
    "        Args:\n",
    "            X (list): List of texts\n",
    "            y (list): List of labels\n",
    "        \n",
    "        Returns: dict: Dictionary of likehoods for each class'''\n",
    "        # Initialize the dictionaries for the words and their counts and the likelihoods\n",
    "        dicts = {c: {} for c in self.labels}\n",
    "        likelihoods = {c: {} for c in self.labels}\n",
    "\n",
    "        # Fill the dictionaries with the words and their counts\n",
    "        for i in range(len(X)):\n",
    "            words = self._preprocess_text_(X[i])\n",
    "            for word in words:\n",
    "                if word in dicts[y[i]]:\n",
    "                    dicts[y[i]][word] += 1\n",
    "                else:\n",
    "                    dicts[y[i]][word] = 1\n",
    "        \n",
    "        # Calculate the likelihoods of each word in each class\n",
    "        for c in self.labels:\n",
    "            for word in dicts[c]:\n",
    "                likelihoods[c][word] = dicts[c][word] / sum(dicts[c].values())\n",
    "\n",
    "        return likelihoods\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.labels = np.unique(y)\n",
    "\n",
    "        self.priors = {c: np.sum(c == y) /len(y) for c in self.labels}\n",
    "\n",
    "        self.likelihoods = self._likelihoods_(X, y)\n",
    "\n",
    "    def predict(self, text):\n",
    "        # Preprocess the text\n",
    "        words = self._preprocess_text_(text)\n",
    "        # Initialize the scores for each class\n",
    "        scores = {c: self.priors[c] for c in self.labels}\n",
    "        \n",
    "        for c in self.labels:\n",
    "            for word in words:\n",
    "                # If the word is in the likelihoods for the class\n",
    "                if word in self.likelihoods[c]:\n",
    "                    # Multiply the class score by the likelihoods of the word in the class\n",
    "                    scores[c] = scores[c] * self.likelihoods[c][word]\n",
    "                # If the word is NOT in the likelihood for the class\n",
    "                else:\n",
    "                    # Set the class score to 0\n",
    "                    scores[c] = 0\n",
    "\n",
    "        # Return the class with the highest score\n",
    "        return max(scores, key=scores.get)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        # To evaluate the model, we use accuracy metric (correct predictions / total predictions)\n",
    "        correct = 0\n",
    "        for i in range(len(X)):\n",
    "            if self.predict(X[i]) == y[i]:\n",
    "                correct += 1\n",
    "        return correct / len(y)\n",
    "\n",
    "    def print(self):\n",
    "        for c in self.labels:\n",
    "            print(f'Class: {c}')\n",
    "            print(f'Prior: {self.priors[c]}')\n",
    "            print(f'Likelihoods: {np.array(self.likelihoods[c])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will use the [SMS Spam Collection Dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) from the UCI Machine Learning Repository. This dataset contains 5574 SMS messages that have been collected for mobile phone spam research. The collection is composed by just one text file, where each line has the correct class followed by the raw message. We will use this dataset to train a Naive Bayes classifier that can classify new messages as spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('../../data/NaiveBayes/SMSSpamCollection.csv', sep='\\t', names=['label', 'message'])\n",
    "stop_words = pd.read_csv('../../data/NaiveBayes/stop_words_EN.txt', delimiter='t', on_bad_lines='skip')\n",
    "stop_words = np.array(stop_words)\n",
    "\n",
    "X = np.array(data.message)\n",
    "y = np.array(data.label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracies: 0.9294708520179372\n",
      "Standard deviation: 0.007950782665996496\n",
      "Minimum accuracies: 0.9139013452914798\n",
      "Maximum accuracies: 0.9461883408071748\n"
     ]
    }
   ],
   "source": [
    "n_tests = 50 # Number of tests to run\n",
    "accuracies = [] # List to store the accuracies\n",
    "\n",
    "model = NaiveBayes(stop_words=stop_words)\n",
    "\n",
    "for i in range(n_tests):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracies.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "print(f'Average accuracies: {np.mean(accuracies)}') # Average score is the mean of the scores => formula: sum(x) / n\n",
    "print(f'Standard deviation: {np.std(accuracies)}') # Standard deviation is a measure of how spread out numbers are => formula: sqrt(sum((x - mean(x))**2) / n)\n",
    "print(f'Minimum accuracies: {np.min(accuracies)}')\n",
    "print(f'Maximum accuracies: {np.max(accuracies)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "This [SMS Spam Collection](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) is public available at the [UCI Machine Learning Repository](https://archive-beta.ics.uci.edu/dataset/228/sms+spam+collection) for research. \n",
    "\n",
    "Tiago A. Almeida and José María Gómez Hidalgo\\\n",
    "Department of Computer Science\\\n",
    "Federal University of Sao Carlos (UFSCar)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

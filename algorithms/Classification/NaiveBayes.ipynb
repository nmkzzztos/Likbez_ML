{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\">Naive Bayes algorithm</h1>\n",
    "\n",
    "<p style=\"text-align: center\">Naive Bayes is a simple probabilistic classifier based on applying Bayes' theorem with <strong>strong (naive) independence assumptions between the features</strong>. It is easy to build and particularly useful for very large data sets. Along with other linear classifiers, Naive Bayes is a good baseline classifier to which more sophisticated methods can be compared.\n",
    "<br>\n",
    "<br>\n",
    "The Naive Bayes classifier is highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. In particular, the parameters of the model are estimated using a \"closed-form\" expression, which takes linear time, rather than iterative approximation as used for many other types of classifiers. This makes it particularly useful for very large data sets. The model is also relatively robust, requiring only a small number of training data to estimate the necessary parameters.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, stop_words=[]):\n",
    "        self.labels = []\n",
    "        self.likelihoods = {}\n",
    "        self.priors = {}\n",
    "        self.stop_words = []\n",
    "\n",
    "    def _preprocess_text_(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess a text by removing punctuation, numbers, and stop words and returning a list of words\n",
    "\n",
    "        Args:\n",
    "            text (float): text to preprocess\n",
    "\n",
    "        Returns: list: List of preprocessed words\n",
    "        \"\"\" \n",
    "        text = str(text)\n",
    "        text = text.encode('ascii', errors='replace').decode('ascii')\n",
    "        text = text.lower()\n",
    "        text = ''.join([c for c in text if c not in '0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'])\n",
    "        text = ' '.join([word for word in text.split() if word not in self.stop_words])\n",
    "\n",
    "        return text.split()\n",
    "    \n",
    "    def _likelihoods_ (self, X, y):\n",
    "        '''\n",
    "        Calculate the likelihoods of each word in each class\n",
    "        \n",
    "        Args:\n",
    "            X (list): List of texts\n",
    "            y (list): List of labels\n",
    "        \n",
    "        Returns: dict: Dictionary of likehoods for each class'''\n",
    "        # Initialize the dictionaries for the words and their counts and the likelihoods\n",
    "        dicts = {c: {} for c in self.labels}\n",
    "        likelihoods = {c: {} for c in self.labels}\n",
    "\n",
    "        # Fill the dictionaries with the words and their counts\n",
    "        for i in range(len(X)):\n",
    "            words = self._preprocess_text_(X[i])\n",
    "            for word in words:\n",
    "                if word in dicts[y[i]]:\n",
    "                    dicts[y[i]][word] += 1\n",
    "                else:\n",
    "                    dicts[y[i]][word] = 1\n",
    "        \n",
    "        # Calculate the likelihoods of each word in each class\n",
    "        for c in self.labels:\n",
    "            for word in dicts[c]:\n",
    "                likelihoods[c][word] = dicts[c][word] / sum(dicts[c].values())\n",
    "\n",
    "        return likelihoods\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.labels = np.unique(y)\n",
    "\n",
    "        self.priors = {c: np.sum(c == y) /len(y) for c in self.labels}\n",
    "\n",
    "        self.likelihoods = self._likelihoods_(X, y)\n",
    "\n",
    "    def predict(self, text):\n",
    "        # Preprocess the text\n",
    "        words = self._preprocess_text_(text)\n",
    "        # Initialize the scores for each class\n",
    "        scores = {c: self.priors[c] for c in self.labels}\n",
    "        \n",
    "        for c in self.labels:\n",
    "            for word in words:\n",
    "                # If the word is in the likelihoods for the class\n",
    "                if word in self.likelihoods[c]:\n",
    "                    # Multiply the class score by the likelihoods of the word in the class\n",
    "                    scores[c] = scores[c] * self.likelihoods[c][word]\n",
    "                # If the word is NOT in the likelihood for the class\n",
    "                else:\n",
    "                    # Set the class score to 0\n",
    "                    scores[c] = 0\n",
    "\n",
    "        # Return the class with the highest score\n",
    "        return max(scores, key=scores.get)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        # To evaluate the model, we use accuracy metric (correct predictions / total predictions)\n",
    "        correct = 0\n",
    "        for i in range(len(X)):\n",
    "            if self.predict(X[i]) == y[i]:\n",
    "                correct += 1\n",
    "        return correct / len(y)\n",
    "\n",
    "    def print(self):\n",
    "        for c in self.labels:\n",
    "            print(f'Class: {c}')\n",
    "            print(f'Prior: {self.priors[c]}')\n",
    "            print(f'Likelihoods: {np.array(self.likelihoods[c])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('../../data/NaiveBayes/SMSSpamCollection.csv', sep='\\t', names=['label', 'message'])\n",
    "stop_words = pd.read_csv('../../data/NaiveBayes/stop_words_EN.txt', delimiter='t', on_bad_lines='skip')\n",
    "stop_words = np.array(stop_words)\n",
    "\n",
    "X = np.array(data.message)\n",
    "y = np.array(data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracies: 0.9294708520179372\n",
      "Standard deviation: 0.007950782665996496\n",
      "Minimum accuracies: 0.9139013452914798\n",
      "Maximum accuracies: 0.9461883408071748\n"
     ]
    }
   ],
   "source": [
    "n_tests = 50 # Number of tests to run\n",
    "accuracies = [] # List to store the accuracies\n",
    "\n",
    "model = NaiveBayes(stop_words=stop_words)\n",
    "\n",
    "for i in range(n_tests):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracies.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "print(f'Average accuracies: {np.mean(accuracies)}') # Average score is the mean of the scores => formula: sum(x) / n\n",
    "print(f'Standard deviation: {np.std(accuracies)}') # Standard deviation is a measure of how spread out numbers are => formula: sqrt(sum((x - mean(x))**2) / n)\n",
    "print(f'Minimum accuracies: {np.min(accuracies)}')\n",
    "print(f'Maximum accuracies: {np.max(accuracies)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "This [SMS Spam Collection](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) is public available at the [UCI Machine Learning Repository](https://archive-beta.ics.uci.edu/dataset/228/sms+spam+collection) for research. \n",
    "\n",
    "Tiago A. Almeida and José María Gómez Hidalgo\\\n",
    "Department of Computer Science\\\n",
    "Federal University of Sao Carlos (UFSCar)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

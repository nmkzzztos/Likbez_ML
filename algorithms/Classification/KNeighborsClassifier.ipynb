{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\">  K-Nearest Neighbors(KNN) algorithm </h1>\n",
    "It's a supervised learning algorithm that can be used for both classification and regression problems. It's a non-parametric algorithm, which means that it doesn't make any assumptions on the underlying data. It's also a lazy learning algorithm, which means that it doesn't learn a discriminative function from the training data but memorizes the training dataset instead.\n",
    "\n",
    "We will dive into classification problem using KNN algorithm.\n",
    "\n",
    "To classify a new data point, we need to find the **distance** between the new data point and all the data points in the training set. Then we need to find the k nearest data points to the new data point. The new data point will be classified based on the majority class of the k nearest data points.\n",
    "\n",
    "<img src=\"../../assets/KNN/example.png\" style=\"width: 1000px; height: 400px; object-fit: cover\"></img>\n",
    "\n",
    "To find the **distance** between two data points, we can use different distance metrics. The most common distance metrics are:\n",
    "\n",
    "$$ Euclidean => d(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2} $$\n",
    "\n",
    "$$ Manhattan => d(x, y) = \\sum_{i=1}^{n}|x_i - y_i| $$\n",
    "\n",
    "To find the majority class of the k nearest data points, we can use majority voting algorithm:\n",
    "\n",
    "$$ Majority\\;Voting => mode(y_1, y_2, ..., y_k) = \\underset{y}{\\operatorname{argmax}}\\sum_{i=1}^{k}I(y_i = y) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNeighborsClassifier:\n",
    "    def __init__(self, k=5, dist_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.dist_metric = dist_metric\n",
    "\n",
    "    def _most_common_(self, arr):\n",
    "        '''\n",
    "        Get the most common element in an array\n",
    "        \n",
    "        Args:\n",
    "            arr: 1D array\n",
    "\n",
    "        return: most common element in arr\n",
    "        '''\n",
    "        return np.bincount(arr).argmax()\n",
    "\n",
    "    def _calculate_distance_(self, points):\n",
    "        '''\n",
    "        Calculate distance between two points using the specified distance metric\n",
    "\n",
    "        Args:\n",
    "            points: 2D array with shape (2, n_features)\n",
    "        \n",
    "        return: distance between two points\n",
    "        '''\n",
    "        if self.dist_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((points[0] - points[1])**2))\n",
    "        elif self.dist_metric == 'manhattan':\n",
    "            return np.abs(points[0] - points[1])\n",
    "        elif self.dist_metric == 'chebychev':\n",
    "            return np.max(np.abs(points[0] - points[1]))\n",
    "        elif self.dist_metric == 'hemming':\n",
    "            return np.sum(points[0] != points[1]) / len(points[0])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            # Calculate distances between x and all training samples\n",
    "            distances = np.array([self._calculate_distance_(np.array([x, x_train])) for x_train in self.X_train])\n",
    "            # Get k nearest samples\n",
    "            k_nearest = np.argsort(distances)[:self.k]\n",
    "            # Get the classes of k nearest samples\n",
    "            y_sorted = self.y_train[k_nearest]\n",
    "            # Append the majority class of the k-nearest samples to predictions\n",
    "            predictions.append(self._most_common_(y_sorted))\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        accuracy = np.sum(self.predict(X) == y) / len(y)\n",
    "\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the performance of the KNN algorithm, we will use the **Iris dataset**. The dataset contains 150 samples of 3 different species of Iris flower (Iris **setosa**, Iris **virginica** and Iris **versicolor**). Four features were measured from each sample: the **length** and the **width** of the **sepals** and **petals**, in centimeters.\n",
    "\n",
    "<img src=\"../../assets/KNN/iris.png\" style=\"width: 800px; height: 350px; object-fit: cover\"></img>\n",
    "\n",
    "The dataset is available in the **sklearn** library. We will use the **train_test_split** function to split the dataset into training and testing sets. We will use 80% of the dataset for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = load_iris().data # 4 features -> sepal length, sepal width, petal length, petal width\n",
    "y = load_iris().target # 3 species of Iris -> 0-setosa, 1-versicolor, 2-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9\n",
      "Accuracy: 0.9\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9666666666666667\n",
      "Average accuracy: 0.9586666666666668\n",
      "Standard deviation: 0.03095516470998373\n",
      "Minimum accuracy: 0.9\n",
      "Maximum accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_tests = 50\n",
    "accuracies = []\n",
    "\n",
    "for i in range(n_tests):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    model = KNeighborsClassifier(k=5, dist_metric='euclidean')\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    accuracies.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "print(f'Average accuracy: {np.mean(accuracies)}') # Average accuracy is the mean of all accuracies => formula is sum(x) / n\n",
    "print(f'Standard deviation: {np.std(accuracies)}') # Standard deviation is a measure of how spread out numbers are => formula is sqrt(sum((x - mean)^2) / n)\n",
    "print(f'Minimum accuracy: {np.min(accuracies)}')\n",
    "print(f'Maximum accuracy: {np.max(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
